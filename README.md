# üöÄ SPA VIP - INTEGRATED NEWS PROCESSING SYSTEM

H·ªá th·ªëng x·ª≠ l√Ω tin t·ª©c t·ª± ƒë·ªông ho√†n ch·ªânh t·ª´ crawl ƒë·∫øn t√≥m t·∫Øt AI v·ªõi ki·∫øn tr√∫c t·∫≠p trung.

## üìÅ C·∫•u tr√∫c d·ª± √°n (C·∫¨P NH·∫¨T)

```
SPA_vip/
‚îú‚îÄ‚îÄ üìÅ crawl/                          # H·ªá th·ªëng crawl tin t·ª©c
‚îÇ   ‚îú‚îÄ‚îÄ main_crawl.py                  # Controller ch√≠nh
‚îÇ   ‚îú‚îÄ‚îÄ crawlers/                      # C√°c crawler c·ª• th·ªÉ
‚îÇ   ‚îú‚îÄ‚îÄ config/                        # C·∫•u h√¨nh crawler c≈© (deprecated)
‚îÇ   ‚îî‚îÄ‚îÄ crawl_stock/                   # Crawler gi√° c·ªï phi·∫øu
‚îÇ
‚îú‚îÄ‚îÄ üìÅ summarization/                  # H·ªá th·ªëng t√≥m t·∫Øt AI
‚îÇ   ‚îú‚îÄ‚îÄ main_summarization.py         # Pipeline t√≥m t·∫Øt
‚îÇ   ‚îú‚îÄ‚îÄ models/                        # Python modules (kh√¥ng c√≥ model weights)
‚îÇ   ‚îú‚îÄ‚îÄ database/                      # Handler c≈© (deprecated)
‚îÇ   ‚îî‚îÄ‚îÄ utils/                         # Utilities
‚îÇ
‚îú‚îÄ‚îÄ üìÅ sentiment/                      # H·ªá th·ªëng ph√¢n t√≠ch sentiment
‚îÇ   ‚îú‚îÄ‚îÄ predict_sentiment_db.py        # D·ª± ƒëo√°n sentiment
‚îÇ   ‚îú‚îÄ‚îÄ optimized_sentiment_update.py  # C·∫≠p nh·∫≠t sentiment t·ªëi ∆∞u
‚îÇ   ‚îî‚îÄ‚îÄ thongke_sentiment_day_db.py    # Th·ªëng k√™ sentiment theo ng√†y
‚îÇ
‚îú‚îÄ‚îÄ üìÅ timeseries/                     # H·ªá th·ªëng d·ª± ƒëo√°n gi√° c·ªï phi·∫øu
‚îÇ   ‚îú‚îÄ‚îÄ main_timeseries.py             # Controller d·ª± ƒëo√°n
‚îÇ   ‚îî‚îÄ‚îÄ load_model_timeseries_db.py    # Load model LSTM
‚îÇ
‚îú‚îÄ‚îÄ üìÅ industry/ üÜï                    # ‚ú® H·ªÜ TH·ªêNG PH√ÇN LO·∫†I NG√ÄNH (M·ªöI)
‚îÇ   ‚îú‚îÄ‚îÄ main.py                        # Controller ph√¢n lo·∫°i ng√†nh
‚îÇ   ‚îú‚îÄ‚îÄ pipeline/                      # Pipeline x·ª≠ l√Ω
‚îÇ   ‚îú‚îÄ‚îÄ models/                        # PhoBERT classifier
‚îÇ   ‚îî‚îÄ‚îÄ utils/                         # Database utilities
‚îÇ
‚îú‚îÄ‚îÄ üìÅ model_AI/ üÜï                    # ‚ú® T·∫§T C·∫¢ AI MODELS (KH√îNG PUSH L√äN GIT)
‚îÇ   ‚îú‚îÄ‚îÄ sentiment_model/               # PhoBERT cho ph√¢n t√≠ch sentiment
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Phobert_hyper_parameters/  # Model weights + training files
‚îÇ   ‚îú‚îÄ‚îÄ summarization_model/           # ViT5 cho t√≥m t·∫Øt tin t·ª©c
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ model_vit5/               # Model weights + config files
‚îÇ   ‚îú‚îÄ‚îÄ timeseries_model/             # LSTM cho d·ª± ƒëo√°n gi√°
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ model_lstm/               # Model weights + training files
‚îÇ   ‚îú‚îÄ‚îÄ industry_model/               # PhoBERT cho ph√¢n lo·∫°i ng√†nh
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ PhoBERT_summary_industry.bin # Model weights
‚îÇ   ‚îî‚îÄ‚îÄ README.md                     # H∆∞·ªõng d·∫´n v·ªÅ c√°c models
‚îÇ
‚îú‚îÄ‚îÄ üìÅ database/                       # ‚ú® H·ªÜ TH·ªêNG DATABASE T·∫¨P TRUNG (M·ªöI)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                    # Package initialization
‚îÇ   ‚îú‚îÄ‚îÄ config.py                      # C·∫•u h√¨nh database
‚îÇ   ‚îú‚îÄ‚îÄ supabase_manager.py            # Manager ch√≠nh
‚îÇ   ‚îú‚îÄ‚îÄ schemas.py                     # Data schemas
‚îÇ   ‚îú‚îÄ‚îÄ test_connection.py             # Test connection
‚îÇ   ‚îî‚îÄ‚îÄ README.md                      # Documentation
‚îÇ
‚îú‚îÄ‚îÄ main.py                            # ‚ú® CONTROLLER CH√çNH (M·ªöI)
‚îú‚îÄ‚îÄ logs/                              # Log files t·ªïng h·ª£p
‚îú‚îÄ‚îÄ .gitignore                         # Lo·∫°i tr·ª´ model_AI/ kh·ªèi Git
‚îî‚îÄ‚îÄ README.md                          # File n√†y
```

## üéØ T√≠nh nƒÉng ch√≠nh

### ‚úÖ H·ªÜ TH·ªêNG CRAWL (`crawl/`)
- **Multi-source crawling**: FireAnt, CafeF, ChungTa, Simplize
- **Smart deduplication**: Tr√°nh crawl tr√πng l·∫∑p
- **Multiple stock codes**: FPT, GAS, IMP, VCB
- **Structured data**: L∆∞u v√†o Supabase v·ªõi schema chu·∫©n

### ‚úÖ H·ªÜ TH·ªêNG T√ìM T·∫ÆT (`summarization/`)
- **AI-powered**: S·ª≠ d·ª•ng ViT5 fine-tuned cho ti·∫øng Vi·ªát
- **Batch processing**: X·ª≠ l√Ω hi·ªáu qu·∫£ nhi·ªÅu b√†i c√πng l√∫c
- **GPU/CPU support**: T·ª± ƒë·ªông t·ªëi ∆∞u theo hardware
- **Table-specific**: C√≥ th·ªÉ x·ª≠ l√Ω t·ª´ng b·∫£ng ri√™ng bi·ªát

### ‚úÖ H·ªÜ TH·ªêNG PH√ÇN T√çCH SENTIMENT (`sentiment/`) - M·ªöI üåü
- **PhoBERT model**: S·ª≠ d·ª•ng PhoBERT fine-tuned cho sentiment ti·∫øng Vi·ªát
- **3-class classification**: Positive, Negative, Neutral
- **Optimized processing**: X·ª≠ l√Ω t·ªëi ∆∞u cho ng√†y giao d·ªãch
- **Real-time analysis**: Ph√¢n t√≠ch sentiment realtime

### ‚úÖ H·ªÜ TH·ªêNG D·ª∞ ƒêO√ÅN GI√Å (`timeseries/`) - M·ªöI üåü  
- **LSTM model**: S·ª≠ d·ª•ng LSTM cho d·ª± ƒëo√°n gi√° c·ªï phi·∫øu
- **15-day window**: D·ª± ƒëo√°n d·ª±a tr√™n 15 ng√†y d·ªØ li·ªáu l·ªãch s·ª≠
- **Multi-stock support**: H·ªó tr·ª£ nhi·ªÅu m√£ c·ªï phi·∫øu
- **Database integration**: T√≠ch h·ª£p v·ªõi database t·∫≠p trung

### ‚úÖ H·ªÜ TH·ªêNG PH√ÇN LO·∫†I NG√ÄNH (`industry/`) - M·ªöI üåü
- **PhoBERT model**: S·ª≠ d·ª•ng PhoBERT fine-tuned cho ph√¢n lo·∫°i ng√†nh
- **5-class classification**: Finance, Technology, Healthcare, Energy, Other
- **Smart processing**: X·ª≠ l√Ω d·ª±a tr√™n ai_summary ho·∫∑c content
- **Batch processing**: X·ª≠ l√Ω hi·ªáu qu·∫£ nhi·ªÅu b√†i c√πng l√∫c

### ‚úÖ H·ªÜ TH·ªêNG AI MODELS (`model_AI/`) - M·ªöI üåü
- **Centralized storage**: T·∫•t c·∫£ AI models ·ªü m·ªôt n∆°i
- **Git-ignored**: Kh√¥ng push l√™n GitHub do k√≠ch th∆∞·ªõc l·ªõn
- **Organized structure**: Ph√¢n chia theo t·ª´ng module r√µ r√†ng
- **Easy deployment**: D·ªÖ d√†ng deploy v√† qu·∫£n l√Ω models

### ‚úÖ H·ªÜ TH·ªêNG DATABASE T·∫¨P TRUNG (`database/`) - M·ªöI üåü
- **Centralized config**: C·∫•u h√¨nh database t·∫≠p trung
- **Schema validation**: Validation d·ªØ li·ªáu t·ª± ƒë·ªông
- **Error handling**: X·ª≠ l√Ω l·ªói to√†n di·ªán
- **Connection management**: Qu·∫£n l√Ω k·∫øt n·ªëi t·ª± ƒë·ªông
- **Statistics**: Built-in monitoring v√† b√°o c√°o

### ‚úÖ CONTROLLER CH√çNH (`main.py`) - M·ªöI üåü
- **Unified interface**: Giao di·ªán duy nh·∫•t cho to√†n b·ªô h·ªá th·ªëng
- **Pipeline orchestration**: ƒêi·ªÅu ph·ªëi crawl ‚Üí summarization
- **Advanced options**: Flexible configuration
- **Comprehensive logging**: Log t·∫≠p trung v·ªõi monitoring
- **Error recovery**: X·ª≠ l√Ω l·ªói v√† recovery t·ª± ƒë·ªông

## üöÄ C√°ch s·ª≠ d·ª•ng (C·∫¨P NH·∫¨T)

### üîß Setup ban ƒë·∫ßu

1. **Install dependencies**:
   ```bash
   # Database dependencies
   pip install -r database/requirements.txt
   
   # Crawl dependencies  
   cd crawl && pip install -r requirements.txt && cd ..
   
   # Summarization dependencies
   cd summarization && pip install -r requirements.txt && cd ..
   ```

2. **Test k·∫øt n·ªëi database**:
   ```bash
   python database/test_connection.py
   ```

3. **üîß C·∫•u h√¨nh Database (N·∫øu c·∫ßn thay ƒë·ªïi)**:
   
   **ƒê·ªÉ thay ƒë·ªïi Supabase URL/KEY c·ªßa b·∫°n:**
   
   ```bash
   # T·∫°o file .env t·ª´ template
   copy .env.example .env
   
   # Ho·∫∑c t·∫°o file .env m·ªõi v·ªõi n·ªôi dung:
   ```
   
   **File `.env`**:
   ```env
   # Thay ƒë·ªïi URL v√† KEY theo database c·ªßa b·∫°n
   SUPABASE_URL=https://your-project-id.supabase.co
   SUPABASE_KEY=your_supabase_anon_key_here
   ```
   
   **üìù L∆∞u √Ω**: 
   - File `.env` s·∫Ω override c√°c gi√° tr·ªã default trong `database/config.py`
   - Kh√¥ng commit file `.env` l√™n Git (ƒë√£ c√≥ trong .gitignore)
   - M·ªói th√†nh vi√™n c√≥ th·ªÉ c√≥ database ri√™ng

4. **‚ö†Ô∏è QUAN TR·ªåNG: Chu·∫©n b·ªã AI Models**
   ```bash
   # T·∫°o folder model_AI n·∫øu ch∆∞a c√≥
   mkdir model_AI
   ```
   
   **üì• T·∫¢I MODELS T·ª™ GOOGLE DRIVE:**
   
   üîó **Link t·∫£i models**: https://drive.google.com/drive/folders/1RctDhes_yJkdLtzqnEIZoHERxW-eaFKS?usp=drive_link
   
   **C·∫•u tr√∫c sau khi t·∫£i v·ªÅ v√† gi·∫£i n√©n:**
   ```
   model_AI/
   ‚îú‚îÄ‚îÄ sentiment_model/
   ‚îÇ   ‚îî‚îÄ‚îÄ Phobert_hyper_parameters/
   ‚îÇ       ‚îî‚îÄ‚îÄ PhoBERT_summary_sentiment_optuna.bin
   ‚îú‚îÄ‚îÄ summarization_model/
   ‚îÇ   ‚îî‚îÄ‚îÄ model_vit5/
   ‚îÇ       ‚îú‚îÄ‚îÄ model.safetensors
   ‚îÇ       ‚îú‚îÄ‚îÄ config.json
   ‚îÇ       ‚îú‚îÄ‚îÄ tokenizer_config.json
   ‚îÇ       ‚îî‚îÄ‚îÄ ... (c√°c file kh√°c)
   ‚îî‚îÄ‚îÄ timeseries_model/
       ‚îî‚îÄ‚îÄ model_lstm/
           ‚îî‚îÄ‚îÄ LSTM_missing10_window15.keras
   ```
   
   **üìù L∆∞u √Ω**: Do models c√≥ k√≠ch th∆∞·ªõc l·ªõn (>100MB), ch√∫ng kh√¥ng ƒë∆∞·ª£c push l√™n Git. 
   C√°c th√†nh vi√™n nh√≥m **B·∫ÆT BU·ªòC** ph·∫£i t·∫£i models t·ª´ Google Drive v√† ƒë·∫∑t v√†o ƒë√∫ng c·∫•u tr√∫c.

### üöÄ Ch·∫°y h·ªá th·ªëng (M·ªöI)

#### **üéØ RECOMMENDED: Full Pipeline**
```bash
python main.py --full                    # Ch·∫°y to√†n b·ªô: crawl ‚Üí summarization
python main.py --full --summ-priority    # Full pipeline v·ªõi priority processing
```

#### **üìä Monitoring & Status**
```bash
python main.py --status                  # Xem tr·∫°ng th√°i h·ªá th·ªëng
python main.py                          # Xem usage v√† tr·∫°ng th√°i
```

#### **üóûÔ∏è Ch·ªâ crawling**
```bash
python main.py --crawl-only              # Ch·∫°y t·∫•t c·∫£ crawler
python main.py --crawl-only --crawl-single fireant_fpt  # Ch·ªâ crawler FPT
```

#### **ü§ñ Ch·ªâ summarization**
```bash
python main.py --summarize-only          # X·ª≠ l√Ω t·∫•t c·∫£ b·∫£ng
python main.py --summarize-only --summ-table FPT_News   # Ch·ªâ b·∫£ng FPT
python main.py --summarize-only --summ-priority         # Theo priority
```

#### **üí≠ Ch·ªâ ph√¢n t√≠ch sentiment**
```bash
python sentiment/predict_sentiment_db.py              # Ph√¢n t√≠ch sentiment cho t·∫•t c·∫£
python sentiment/optimized_sentiment_update.py        # C·∫≠p nh·∫≠t sentiment t·ªëi ∆∞u
```

#### **üìà Ch·ªâ d·ª± ƒëo√°n gi√° c·ªï phi·∫øu**
```bash
python timeseries/main_timeseries.py --stock FPT       # D·ª± ƒëo√°n gi√° FPT
python timeseries/main_timeseries.py --all             # D·ª± ƒëo√°n t·∫•t c·∫£ c·ªï phi·∫øu
```

#### **üè≠ Ch·ªâ ph√¢n lo·∫°i ng√†nh c√¥ng nghi·ªáp**
```bash
python main.py --industry-only                        # Ph√¢n lo·∫°i t·∫•t c·∫£ b·∫£ng
python main.py --industry-only --ind-tables FPT_News  # Ch·ªâ b·∫£ng FPT
python main.py --industry-only --ind-batch-size 100   # Batch size t√πy ch·ªânh
```

### üéõÔ∏è Advanced Options

```bash
# Combinations
python main.py --full --crawl-single fireant_fpt --summ-table FPT_News
python main.py --full --summ-priority

# Help
python main.py --help
```

## üìä Database Schema (Chu·∫©n h√≥a)

### Tables tin t·ª©c:
- `FPT_News`, `GAS_News`, `IMP_News`, `VCB_News`: Tin t·ª©c theo t·ª´ng m√£ c·ªï phi·∫øu
- `General_News`: Tin t·ª©c chung

### Tables gi√° c·ªï phi·∫øu:
- `FPT_Stock`, `GAS_Stock`, `IMP_Stock`, `VCB_Stock`: D·ªØ li·ªáu gi√° v√† sentiment

### C·∫•u tr√∫c b·∫£ng News:
```sql
CREATE TABLE <STOCK>_News (
    id bigint PRIMARY KEY,
    title text NOT NULL,
    content text NOT NULL,
    date date NOT NULL,
    link text UNIQUE NOT NULL,
    ai_summary text,     -- ƒê∆∞·ª£c ƒëi·ªÅn b·ªüi summarization
    sentiment text,      -- ƒê∆∞·ª£c ƒëi·ªÅn b·ªüi sentiment analysis
    industry text        -- ƒê∆∞·ª£c ƒëi·ªÅn b·ªüi industry classification
);
```

### C·∫•u tr√∫c b·∫£ng Stock:
```sql
CREATE TABLE <STOCK>_Stock (
    id bigint PRIMARY KEY,
    date date NOT NULL,
    open numeric,
    high numeric,
    low numeric,
    close numeric,
    volume bigint,
    positive integer DEFAULT 0,    -- S·ªë tin t√≠ch c·ª±c
    negative integer DEFAULT 0,    -- S·ªë tin ti√™u c·ª±c  
    neutral integer DEFAULT 0,     -- S·ªë tin trung t√≠nh
    predicted_price numeric        -- Gi√° d·ª± ƒëo√°n t·ª´ LSTM
);
```

## üîÑ Workflow m·ªõi (T·ªëi ∆∞u)

```mermaid
graph LR
    A[main.py] --> B[Database Manager]
    B --> C[Crawl Phase]
    C --> D[Supabase Storage]
    D --> E[Summarization Phase]
    E --> F[Sentiment Analysis]
    F --> G[Price Prediction]  
    G --> H[Industry Classification]
    H --> I[Complete Pipeline]
```

1. **Initialization**: `main.py` kh·ªüi t·∫°o database manager t·∫≠p trung
2. **Crawl Phase**: Thu th·∫≠p tin t·ª©c t·ª´ c√°c ngu·ªìn ‚Üí Supabase
3. **Wait Period**: 10 gi√¢y ngh·ªâ gi·ªØa c√°c phase
4. **Summarization Phase**: AI t·∫°o t√≥m t·∫Øt cho articles ch∆∞a c√≥
5. **Sentiment Analysis**: PhoBERT ph√¢n t√≠ch sentiment cho tin t·ª©c
6. **Price Prediction**: LSTM d·ª± ƒëo√°n gi√° c·ªï phi·∫øu d·ª±a tr√™n d·ªØ li·ªáu l·ªãch s·ª≠
7. **Industry Classification**: PhoBERT ph√¢n lo·∫°i tin t·ª©c theo ng√†nh c√¥ng nghi·ªáp
8. **Monitoring**: B√°o c√°o t·ªïng k·∫øt v√† statistics

## üìà Performance hi·ªán t·∫°i

### **System Status:**
- **Total Articles**: 1,037
- **AI Summarized**: 1,035 (99.8%)
- **Sentiment Analyzed**: ~1,000+ articles
- **Price Predictions**: Daily predictions cho 4 m√£ c·ªï phi·∫øu
- **Pending**: 2 articles

### **Table Breakdown:**
- **General_News**: 331/331 (100.0%)
- **FPT_News**: 434/436 (99.5%)
- **GAS_News**: 74/74 (100.0%)
- **IMP_News**: 96/96 (100.0%)
- **VCB_News**: 100/100 (100.0%)

### **Processing Speed:**
- **Crawling**: ~100-200 articles/hour
- **GPU Summarization**: ~300-500 articles/hour
- **CPU Summarization**: ~100-200 articles/hour
- **Sentiment Analysis**: ~500-1000 articles/hour
- **Price Prediction**: ~4 stocks/minute

## üõ†Ô∏è Troubleshooting (C·∫≠p nh·∫≠t)

### L·ªói database connection
```bash
python database/test_connection.py       # Test connection

# N·∫øu mu·ªën thay ƒë·ªïi database, t·∫°o file .env:
# SUPABASE_URL=https://your-project-id.supabase.co
# SUPABASE_KEY=your_supabase_anon_key_here
```

### L·ªói AI models kh√¥ng t√¨m th·∫•y
```bash
# Ki·ªÉm tra models c√≥ t·ªìn t·∫°i kh√¥ng:
ls model_AI/sentiment_model/Phobert_hyper_parameters/
ls model_AI/summarization_model/model_vit5/
ls model_AI/timeseries_model/model_lstm/

# N·∫øu thi·∫øu models, t·∫£i t·ª´ Google Drive:
# https://drive.google.com/drive/folders/1RctDhes_yJkdLtzqnEIZoHERxW-eaFKS?usp=drive_link
```

### L·ªói import ho·∫∑c missing dependencies
```bash
pip install -r database/requirements.txt
pip install -r crawl/requirements.txt
pip install -r summarization/requirements.txt
```

### Out of memory (Summarization)
- Gi·∫£m `BATCH_SIZE` trong summarization config
- Chuy·ªÉn t·ª´ GPU sang CPU mode

### L·ªói crawl
```bash
python main.py --crawl-only --crawl-single fireant_fpt  # Test single crawler
```

### L·ªói sentiment analysis
```bash
python sentiment/predict_sentiment_db.py --test  # Test sentiment model
```

### L·ªói price prediction  
```bash
python timeseries/load_model_timeseries_db.py    # Test LSTM model
```

## üéØ M·ªü r·ªông t∆∞∆°ng lai

- [x] **Centralized Database**: ‚úÖ Ho√†n th√†nh
- [x] **Unified Controller**: ‚úÖ Ho√†n th√†nh
- [x] **Advanced CLI**: ‚úÖ Ho√†n th√†nh
- [x] **Sentiment Analysis**: ‚úÖ Ho√†n th√†nh - PhoBERT ph√¢n t√≠ch sentiment
- [x] **Price Prediction**: ‚úÖ Ho√†n th√†nh - LSTM d·ª± ƒëo√°n gi√° c·ªï phi·∫øu
- [x] **Model Organization**: ‚úÖ Ho√†n th√†nh - T·ªï ch·ª©c models trong model_AI/
- [ ] **Real-time Processing**: X·ª≠ l√Ω real-time
- [ ] **Web Dashboard**: Dashboard monitoring
- [ ] **REST API**: API cho external integration
- [ ] **Docker Support**: Containerization
- [ ] **Automated Scheduling**: Cron jobs
- [ ] **Advanced Analytics**: Ph√¢n t√≠ch s√¢u h∆°n sentiment vs price correlation

## üìû Support

### Quick Commands:
```bash
python main.py --status                  # Ki·ªÉm tra tr·∫°ng th√°i
python database/test_connection.py       # Test database
python main.py --help                    # Xem help
```

### Database Configuration:
```bash
# ƒê·ªÉ thay ƒë·ªïi database c·ªßa b·∫°n:
copy .env.example .env                   # T·∫°o file .env
# S·ª≠a SUPABASE_URL v√† SUPABASE_KEY trong .env
python database/test_connection.py       # Test connection
```

üìñ **Chi ti·∫øt**: Xem `database/DATABASE_CONFIG.md`

### Workflow Testing:
```bash
python main.py --crawl-only              # Test crawling
python main.py --summarize-only          # Test summarization  
python sentiment/predict_sentiment_db.py # Test sentiment analysis
python timeseries/main_timeseries.py     # Test price prediction
python main.py --full                    # Test full pipeline
```

### Model Testing:
```bash
# Ki·ªÉm tra c√°c models c√≥ ho·∫°t ƒë·ªông kh√¥ng
python -c "import torch; print('PyTorch:', torch.__version__)"
python -c "from transformers import T5Tokenizer; print('Transformers OK')"
python -c "import tensorflow as tf; print('TensorFlow:', tf.__version__)"
```

### üìÇ C·∫•u tr√∫c model_AI c·∫ßn thi·∫øt:
```
model_AI/
‚îú‚îÄ‚îÄ sentiment_model/Phobert_hyper_parameters/PhoBERT_summary_sentiment_optuna.bin
‚îú‚îÄ‚îÄ summarization_model/model_vit5/model.safetensors  
‚îî‚îÄ‚îÄ timeseries_model/model_lstm/LSTM_missing10_window15.keras
```

### üì• T·∫¢I MODELS:
**Google Drive**: https://drive.google.com/drive/folders/1RctDhes_yJkdLtzqnEIZoHERxW-eaFKS?usp=drive_link

**H∆∞·ªõng d·∫´n**:
1. T·∫£i to√†n b·ªô folder t·ª´ Google Drive
2. Gi·∫£i n√©n v√† ƒë·∫∑t v√†o ƒë√∫ng c·∫•u tr√∫c `model_AI/`
3. Ch·∫°y l·ªánh test ƒë·ªÉ ki·ªÉm tra

---

**üéâ H·ªá th·ªëng ho√†n ch·ªânh v·ªõi 4 modules ch√≠nh: Crawling ‚Üí Summarization ‚Üí Sentiment Analysis ‚Üí Price Prediction!**

**‚ö†Ô∏è H∆Ø·ªöNG D·∫™N CHO TEAM**:
1. **T·∫£i models**: https://drive.google.com/drive/folders/1RctDhes_yJkdLtzqnEIZoHERxW-eaFKS?usp=drive_link
2. **ƒê·∫∑t v√†o folder** `model_AI/` theo ƒë√∫ng c·∫•u tr√∫c
3. **Test tr∆∞·ªõc khi ch·∫°y**: `python main.py --status`
