import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler
from datetime import timedelta
import os
import sys

# Add parent directory for imports
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)

try:
    from supabase import create_client, Client
    SUPABASE_AVAILABLE = True
except ImportError:
    SUPABASE_AVAILABLE = False
    print("‚ö†Ô∏è Supabase not installed. Install with: pip install supabase")

# Try to import centralized database (optional for backwards compatibility)
try:
    from database import SupabaseManager, DatabaseConfig
    CENTRALIZED_DB_AVAILABLE = True
except ImportError:
    CENTRALIZED_DB_AVAILABLE = False


class StockPredictor:
    DEFAULT_SUPABASE_URL = "https://baenxyqklayjtlbmubxe.supabase.co"
    DEFAULT_SUPABASE_KEY = "sb_secret_4Mj3OwBW9VlbhVU6bVrfLA_1olLCYpp"

    def __init__(self, model_path, supabase_config, use_centralized_db=True):
        self.model_path = model_path
        self.supabase_config = supabase_config
        self.model = None
        self.scaler = MinMaxScaler()
        self.window_size = 15  # ‚úÖ L·∫•y ƒë√∫ng 15 ng√†y
        self.features = ["Gi√° ƒë√≥ng c·ª≠a", "Positive", "Negative"]
        self.use_centralized_db = use_centralized_db

        # Prioritize centralized database if available
        if use_centralized_db and CENTRALIZED_DB_AVAILABLE:
            try:
                self.db_manager = SupabaseManager()
                self.supabase = self.db_manager.client
                self.table_name = supabase_config["table_name"]
                print(f"‚úÖ Using centralized database for table: {self.table_name}")
            except Exception as e:
                print(f"‚ö†Ô∏è Failed to use centralized database, falling back: {e}")
                self.use_centralized_db = False
                self._setup_direct_connection(supabase_config)
        else:
            self._setup_direct_connection(supabase_config)

    def _setup_direct_connection(self, supabase_config):
        """Setup direct supabase connection as fallback"""
        if SUPABASE_AVAILABLE:
            self.supabase: Client = create_client(
                supabase_config["url"], supabase_config["key"]
            )
            self.table_name = supabase_config["table_name"]
            print(f"‚ö†Ô∏è Using direct connection for table: {self.table_name}")
        else:
            self.supabase = None

    @classmethod
    def create_default_supabase_config(cls, table_name):
        return {
            "url": cls.DEFAULT_SUPABASE_URL,
            "key": cls.DEFAULT_SUPABASE_KEY,
            "table_name": table_name,
        }

    def load_model(self):
        # Try using model manager for HuggingFace models
        try:
            from models.model_manager import get_model_manager
            manager = get_model_manager()
            self.model = manager.load_timeseries_model()
            print("‚úÖ Model loaded via ModelManager from HuggingFace")
            return True
        except Exception as e:
            print(f"‚ùå Failed to load timeseries model: {e}")
            raise RuntimeError("Unable to load timeseries model. Please ensure HuggingFace models are available.")

    def load_last_window_data(self):
        """L·∫•y d·ªØ li·ªáu window_size ng√†y g·∫ßn nh·∫•t c√≥ close_price (15 ng√†y cho model hi·ªán t·∫°i)"""
        if not self.supabase:
            print("‚ùå Supabase client not initialized!")
            return None

        try:
            response = (
                self.supabase.table(self.table_name)
                .select("*")
                .neq("close_price", "")
                .not_.is_("close_price", "null")
                .order("date", desc=True)
                .limit(self.window_size)  # S·ª≠ d·ª•ng window_size thay v√¨ hardcode 15
                .execute()
            )

            if not response.data:
                print("‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu close_price!")
                return None

            df = pd.DataFrame(response.data)
            df["Ng√†y"] = pd.to_datetime(df["date"])
            df["Gi√° ƒë√≥ng c·ª≠a"] = pd.to_numeric(
                df["close_price"].astype(str).str.replace(",", ""),
                errors="coerce",
            )

            df = df.sort_values("Ng√†y").reset_index(drop=True)

            # X·ª≠ l√Ω sentiment - ƒë·∫£m b·∫£o t·∫•t c·∫£ columns c√≥ gi√° tr·ªã s·ªë
            for col in ["Positive", "Neutral", "Negative"]:
                if col not in df.columns:
                    df[col] = 0
                else:
                    df[col] = (
                        pd.to_numeric(df[col].replace("", "0"), errors="coerce")
                        .fillna(0)
                    )

            print(f"‚úÖ L·∫•y th√†nh c√¥ng {len(df)} ng√†y g·∫ßn nh·∫•t (window_size={self.window_size})")
            
            # Hi·ªÉn th·ªã chi ti·∫øt 15 ng√†y nh∆∞ y√™u c·∫ßu
            print("\nüìã CHI TI·∫æT 15 NG√ÄY:")
            print("-" * 90)
            print(f"{'STT':<4} {'Ng√†y':<12} {'Gi√° ƒë√≥ng c·ª≠a':<15} {'Positive':<10} {'Neutral':<10} {'Negative':<10}")
            print("-" * 90)
            
            for idx, row in df.iterrows():
                stt = idx + 1
                ngay = row['Ng√†y'].strftime('%Y-%m-%d')
                gia = f"{row['Gi√° ƒë√≥ng c·ª≠a']:,.0f}"
                pos = f"{row['Positive']:.0f}"
                neu = f"{row['Neutral']:.0f}"
                neg = f"{row['Negative']:.0f}"
                
                print(f"{stt:<4} {ngay:<12} {gia:<15} {pos:<10} {neu:<10} {neg:<10}")
            
            print("-" * 90)
            return df

        except Exception as e:
            print(f"‚ùå Error loading last days: {e}")
            return None

    def fit_scaler(self, df):
        scaled = self.scaler.fit_transform(df[self.features])
        return scaled

    def predict_next_10_days(self, df):
        if self.model is None:
            print("‚ùå Model not loaded!")
            return None, None

        scaled_data = self.fit_scaler(df)
        last_window = scaled_data[-self.window_size:].tolist()
        predictions_scaled = []

        for _ in range(10):
            x_input = np.array([last_window])
            pred = self.model.predict(x_input, verbose=0)[0][0]
            next_input = [pred, 0, 0]
            last_window.append(next_input)
            last_window.pop(0)
            predictions_scaled.append([pred, 0, 0])

        predicted_prices = self.scaler.inverse_transform(
            np.array(predictions_scaled)
        )[:, 0]

        last_date = df["Ng√†y"].iloc[-1]
        future_dates = [last_date + timedelta(days=i + 1) for i in range(10)]

        return future_dates, predicted_prices

    def update_existing_predictions(self, prediction_dates, predicted_prices):
        if not self.supabase:
            print("‚ùå Supabase client not initialized!")
            return False

        updated, inserted = 0, 0

        for date, price in zip(prediction_dates, predicted_prices):
            date_str = date.strftime("%Y-%m-%d")

            existing = (
                self.supabase.table(self.table_name)
                .select("id")
                .eq("date", date_str)
                .execute()
            )

            if existing.data:
                self.supabase.table(self.table_name).update(
                    {"predict_price": f"{price:,.0f}"}
                ).eq("date", date_str).execute()
                updated += 1
            else:
                record = {
                    "date": date_str,
                    "open_price": "",
                    "high_price": "",
                    "low_price": "",
                    "close_price": "",
                    "change": "",
                    "change_pct": "",
                    "volume": "",
                    "Positive": "",
                    "Neutral": "",
                    "Negative": "",
                    "predict_price": f"{int(price):,}",
                }
                self.supabase.table(self.table_name).insert(record).execute()
                inserted += 1

        print(f"‚úÖ Updated: {updated}, Inserted: {inserted}")
        return True


def run_prediction_for_table(model_path, table_name):
    """
    Run prediction for a single table
    
    Args:
        model_path: Path to the model file
        table_name: Name of the table to predict (e.g., 'GAS_Stock')
    """
    config = StockPredictor.create_default_supabase_config(table_name)
    predictor = StockPredictor(model_path, config)

    if not predictor.load_model():
        return False

    df_last_days = predictor.load_last_window_data()
    if df_last_days is None or len(df_last_days) < predictor.window_size:
        print(f"‚ùå Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ d·ª± ƒëo√°n! C·∫ßn √≠t nh·∫•t {predictor.window_size} ng√†y, c√≥ {len(df_last_days) if df_last_days is not None else 0} ng√†y")
        return False

    future_dates, pred_prices = predictor.predict_next_10_days(df_last_days)

    if future_dates is not None:
        success = predictor.update_existing_predictions(future_dates, pred_prices)
        print(f"\nüìà D·ª± ƒëo√°n 10 ng√†y ti·∫øp theo cho {table_name}:")
        for d, p in zip(future_dates, pred_prices):
            print(f"{d.strftime('%Y-%m-%d')}: {p:,.0f} VND")
        return success
    
    return False


def main():
    """Main function for standalone testing"""
    # Test with multiple tables (no longer using local model path)
    tables = ["FPT_Stock", "GAS_Stock", "IMP_Stock", "VCB_Stock"]
    
    print("\nüöÄ SPA VIP TIMESERIES PREDICTION")
    print("="*60)
    
    successful_predictions = 0
    total_tables = len(tables)
    
    for table in tables:
        print("\n" + "=" * 50)
        print(f"üöÄ ƒêang x·ª≠ l√Ω {table}")
        print("=" * 50)
        
        try:
            # Use empty model_path since we'll load from HuggingFace
            success = run_prediction_for_table("", table)
            if success:
                successful_predictions += 1
                print(f"‚úÖ {table}: D·ª± ƒëo√°n th√†nh c√¥ng")
            else:
                print(f"‚ùå {table}: D·ª± ƒëo√°n th·∫•t b·∫°i")
        except Exception as e:
            print(f"‚ùå {table}: L·ªói - {e}")
    
    print("\n" + "="*60)
    print("üìä SUMMARY")
    print("="*60)
    print(f"‚úÖ Successful: {successful_predictions}/{total_tables}")
    print(f"‚ùå Failed: {total_tables - successful_predictions}/{total_tables}")
    print(f"üìà Success rate: {successful_predictions/total_tables*100:.1f}%")


if __name__ == "__main__":
    main()
